{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.0"},"colab":{"name":"C5_Assignment.ipynb","provenance":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"kj6QBzZzS_Dz"},"source":["# Text Retrieval\n","There are 2 standard models for retrieving text data.\n","1. Boolean Retrieval Model\n","2. Vector Space Model\n","\n","The aim of any information retrieval model is to retrieve documents related to a query."]},{"cell_type":"markdown","metadata":{"id":"JMfkLtvqS_Dz"},"source":["## 1. Boolean Retrieval Model\n","In this model we consider every query and document as a set of words and we retrieve a document if and only if the query word is present in it. Model can be extended to support complex queries with boolean operators.\n","\n","In this assignment we are going to implement both the models, using scikit-learn package. We are going to use song lyrics dataset.\n","\n","\n","**Step 1. Import necessary packages -- numpy and pandas - 1 Mark** "]},{"cell_type":"code","metadata":{"id":"ESbfOi1XS_Dz","executionInfo":{"status":"ok","timestamp":1605718812266,"user_tz":-330,"elapsed":4063,"user":{"displayName":"Ram Sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjzX5wQmyNJusIIjmpQoEKHMpdthKozyZspvGj9vQ=s64","userId":"18260499514739068954"}}},"source":["import pandas as pd\n","import numpy as np"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"e8RQWIp_S_D0"},"source":["**Step 2. Read the dataset and store it in variable 'df' - 1 mark** <br> \n","\n","The lyric column of the dataset has song lyrics. We aim to give some lyrics as a query and retrieve the song name. \n"]},{"cell_type":"code","metadata":{"id":"kXglxb6LS_D0","executionInfo":{"status":"error","timestamp":1605718812283,"user_tz":-330,"elapsed":4070,"user":{"displayName":"Ram Sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjzX5wQmyNJusIIjmpQoEKHMpdthKozyZspvGj9vQ=s64","userId":"18260499514739068954"}},"outputId":"90462a55-1e49-483a-b796-79c9ec51e4dc","colab":{"base_uri":"https://localhost:8080/","height":425}},"source":["\n","df = pd.read_csv(\"modified_song_lyrics.csv\")\n","\n","#df.head()"],"execution_count":2,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-46b6f3a9a44f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"modified_song_lyrics.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#df.head()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'modified_song_lyrics.csv'"]}]},{"cell_type":"markdown","metadata":{"id":"6grq0KkRS_D0"},"source":["**Documentation Reference: https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html**<br>"]},{"cell_type":"markdown","metadata":{"id":"Ox-yyuTGS_D0"},"source":["**Step 3**<br>\n","1. Import this class\n","2. Create a 'vectorizer' object of 'CountVectorizer' with parameter binary=True - 1 Mark"]},{"cell_type":"code","metadata":{"id":"1WbjoUObS_D0","executionInfo":{"status":"aborted","timestamp":1605718812268,"user_tz":-330,"elapsed":4048,"user":{"displayName":"Ram Sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjzX5wQmyNJusIIjmpQoEKHMpdthKozyZspvGj9vQ=s64","userId":"18260499514739068954"}}},"source":["from sklearn.feature_extraction.text import CountVectorizer\n","count_vectorizer = CountVectorizer(binary=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bI_XtBZNS_D0"},"source":["We aim to analyze the lyrics for presence or absence. <br> \n","**Step 4. Fit and transform the lyric column using vectorizer - 2 Marks**<br>\n","X object is a matrix of size (n_songs,n_unique_words) where each entry is 0 or 1 if the word in present in this song. Verify this using X.shape method"]},{"cell_type":"code","metadata":{"id":"NQeBPL50S_D1","executionInfo":{"status":"aborted","timestamp":1605718812269,"user_tz":-330,"elapsed":4026,"user":{"displayName":"Ram Sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjzX5wQmyNJusIIjmpQoEKHMpdthKozyZspvGj9vQ=s64","userId":"18260499514739068954"}}},"source":["X = count_vectorizer.fit_transform(df['lyric'])\n","X.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8JH4Ok47S_D3","executionInfo":{"status":"aborted","timestamp":1605718812270,"user_tz":-330,"elapsed":4021,"user":{"displayName":"Ram Sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjzX5wQmyNJusIIjmpQoEKHMpdthKozyZspvGj9vQ=s64","userId":"18260499514739068954"}}},"source":["query1 = 'beautiful'\n","query2 = 'girl'\n","# To get list of all doc containing a word, we do it in the following way\n","list_q1 = X[:,count_vectorizer.vocabulary_[query1]]\n","# Step 5. Do the same for 'query2' and store it in 'list_q2'\n","list_q2 = X[:,count_vectorizer.vocabulary_[query2]]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DIIXNCcmS_D3","executionInfo":{"status":"aborted","timestamp":1605718812271,"user_tz":-330,"elapsed":4013,"user":{"displayName":"Ram Sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjzX5wQmyNJusIIjmpQoEKHMpdthKozyZspvGj9vQ=s64","userId":"18260499514739068954"}}},"source":["# AND Operation\n","for i in range(list_q1.shape[0]):\n","    if list_q1[i]==1 and list_q2[i]==1:\n","        print(df.iloc[i,1])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UkKnWkAiS_D3"},"source":["**Step 6. Implement OR operation - 1 Mark**"]},{"cell_type":"code","metadata":{"id":"mzhfFGf4S_D3","executionInfo":{"status":"aborted","timestamp":1605718812272,"user_tz":-330,"elapsed":4003,"user":{"displayName":"Ram Sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjzX5wQmyNJusIIjmpQoEKHMpdthKozyZspvGj9vQ=s64","userId":"18260499514739068954"}}},"source":["# OR Operation\n","for i in range(list_q1.shape[0]):\n","    if list_q1[i]==1 or list_q2[i]==1:\n","        print(df.iloc[i,1])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lHl1e8VXS_D4"},"source":["## 2. Vector Space Model\n","In this model, every document and query is represented as a vector and closest vector as measured by cosine distance is considered as the correct answer."]},{"cell_type":"markdown","metadata":{"id":"chU1Le3gS_D4"},"source":["**Documentation Reference:**<br>\n","1. https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\n","2. https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.cosine_similarity.html\n","\n","**Step 1. Import above references - 1 Mark**"]},{"cell_type":"code","metadata":{"id":"jx8EolPHS_D4","executionInfo":{"status":"aborted","timestamp":1605718812273,"user_tz":-330,"elapsed":3999,"user":{"displayName":"Ram Sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjzX5wQmyNJusIIjmpQoEKHMpdthKozyZspvGj9vQ=s64","userId":"18260499514739068954"}}},"source":["from sklearn.feature_extraction.text import TfidfVectorizer"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WYRwJ3GuS_D4"},"source":["**Step 2. Create a 'vectorizer' object of 'TfidfVectorizer' - 1 Mark**"]},{"cell_type":"code","metadata":{"id":"_Zx7xX-3S_D4","executionInfo":{"status":"aborted","timestamp":1605718812274,"user_tz":-330,"elapsed":3992,"user":{"displayName":"Ram Sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjzX5wQmyNJusIIjmpQoEKHMpdthKozyZspvGj9vQ=s64","userId":"18260499514739068954"}}},"source":["tfidf_vectorizer = TfidfVectorizer()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"U8w7sXl3S_D4"},"source":["Here we attempt to calculate tf-idf scores of the terms (lyrics). We do that by doing the following. <br> \n","**Step 3. Fit and transform the lyric column using vectorizer - 2 Marks**<br>\n","X object is a matrix of size (n_songs,n_unique_words) where each entry is tf-idf score of the word in this song. Verify this using X.shape method"]},{"cell_type":"code","metadata":{"id":"DEpit6VMS_D4","executionInfo":{"status":"aborted","timestamp":1605718812275,"user_tz":-330,"elapsed":3979,"user":{"displayName":"Ram Sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjzX5wQmyNJusIIjmpQoEKHMpdthKozyZspvGj9vQ=s64","userId":"18260499514739068954"}}},"source":["X = tfidf_vectorizer.fit_transform(df['lyric'])\n","X.shape"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"54WIyTC0S_D4"},"source":["**Step 4. Use 'transform' method of vectorizer on 'query' and store in 'query_vec' - 1 Mark**<br>\n","This method converts a text value into a tf-idf vector"]},{"cell_type":"code","metadata":{"id":"7Kq78-3DS_D4","executionInfo":{"status":"aborted","timestamp":1605718812276,"user_tz":-330,"elapsed":3970,"user":{"displayName":"Ram Sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjzX5wQmyNJusIIjmpQoEKHMpdthKozyZspvGj9vQ=s64","userId":"18260499514739068954"}}},"source":["query = \"Take it easy, with me\"\n","query_vec = tfidf_vectorizer.transform([query])\n","\n","query_vec.shape"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YUA6rUZ4S_D4"},"source":["**Step 5. Use 'cosine_similarity' on 'X' and 'query_vec' store it in 'results' - 1 Mark**"]},{"cell_type":"code","metadata":{"id":"UsSUwMkNS_D4","executionInfo":{"status":"aborted","timestamp":1605718812277,"user_tz":-330,"elapsed":3966,"user":{"displayName":"Ram Sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjzX5wQmyNJusIIjmpQoEKHMpdthKozyZspvGj9vQ=s64","userId":"18260499514739068954"}}},"source":["from sklearn.metrics.pairwise import cosine_similarity\n","\n","results = cosine_similarity(X, query_vec)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"j53-BCwlS_D4","executionInfo":{"status":"aborted","timestamp":1605718812279,"user_tz":-330,"elapsed":3958,"user":{"displayName":"Ram Sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjzX5wQmyNJusIIjmpQoEKHMpdthKozyZspvGj9vQ=s64","userId":"18260499514739068954"}}},"source":["# Print Name of the song\n","song_index = np.argmax(results.reshape((-1,)))\n","print('Song -- ', df.iloc[song_index,1]) # add song name here "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MnLHQWGMS_D4","executionInfo":{"status":"aborted","timestamp":1605718812281,"user_tz":-330,"elapsed":3954,"user":{"displayName":"Ram Sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjzX5wQmyNJusIIjmpQoEKHMpdthKozyZspvGj9vQ=s64","userId":"18260499514739068954"}}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tRcFxztXS_D4","executionInfo":{"status":"aborted","timestamp":1605718812282,"user_tz":-330,"elapsed":3951,"user":{"displayName":"Ram Sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjzX5wQmyNJusIIjmpQoEKHMpdthKozyZspvGj9vQ=s64","userId":"18260499514739068954"}}},"source":[""],"execution_count":null,"outputs":[]}]}