{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution (b) - Perform data discretization using Chi-Merge method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "## crucial libs\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 5)\n",
      "   sepal_length  sepal_width  petal_length  petal_width    iris_type\n",
      "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
      "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
      "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
      "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
      "4           5.0          3.6           1.4          0.2  Iris-setosa\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   sepal_length  150 non-null    float64\n",
      " 1   sepal_width   150 non-null    float64\n",
      " 2   petal_length  150 non-null    float64\n",
      " 3   petal_width   150 non-null    float64\n",
      " 4   iris_type     150 non-null    object \n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 5.3+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#now reading Iris dataset from the url\n",
    "iris = pd.read_csv('http://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data', header=None)\n",
    "\n",
    "# as the data set does not have column header, adding header\n",
    "iris.columns = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'iris_type']\n",
    "\n",
    "#Lets see some data\n",
    "print(iris.shape)\n",
    "print(iris.head())\n",
    "print(iris.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chi-Merge Algorithm implementaion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "## now implementing chi-merge algorithm\n",
    "def chi_merge(data, attr, label, max_intervals):\n",
    "    \n",
    "    # if division by zero error, ignore\n",
    "    np.seterr(divide='ignore', invalid='ignore')\n",
    "    \n",
    "    # distinct sorted values of the given features\n",
    "    distinct_vals = sorted(set(data[attr]))  \n",
    "    \n",
    "    # distinct sorted labels\n",
    "    labels = sorted(set(data[label]))  \n",
    "    \n",
    "    # dictionary of counts for each label\n",
    "    empty_count = {l: 0 for l in labels}  \n",
    "    \n",
    "    # initializing the intervals for the given attribute; to start with each row is taken as an interval\n",
    "    intervals = [[distinct_vals[i], distinct_vals[i]] for i in range(len(distinct_vals))] \n",
    " \n",
    "    # Keep applying chimerge process as long as we reach the max_intervals condition\n",
    "    while len(intervals) > max_intervals:\n",
    "        \n",
    "        #Array to hold the chi values for this iteration\n",
    "        chi = []\n",
    "        \n",
    "        #Calculate chi values for each consecutive intervals in this iteration\n",
    "        for i in range(len(intervals)-1):\n",
    "            \n",
    "            # Indexes of the attribute that falls between given interval \n",
    "            obs0 = data[data[attr].between(intervals[i][0], intervals[i][1])]\n",
    "            obs1 = data[data[attr].between(intervals[i+1][0], intervals[i+1][1])]\n",
    "            total = len(obs0) + len(obs1)\n",
    "            \n",
    "            #Count the values for each label for given attribute\n",
    "            count_0 = np.array([v for i, v in {**empty_count, **Counter(obs0[label])}.items()])\n",
    "            count_1 = np.array([v for i, v in {**empty_count, **Counter(obs1[label])}.items()])\n",
    "            count_total = count_0 + count_1\n",
    "            \n",
    "            #Caclculate expected values\n",
    "            expected_0 = count_total*sum(count_0)/total\n",
    "            expected_1 = count_total*sum(count_1)/total\n",
    "  \n",
    "            # Calculate the Chi2 value\n",
    "            chi_ = (count_0 - expected_0)**2/expected_0 + (count_1 - expected_1)**2/expected_1\n",
    "            chi_ = np.nan_to_num(chi_) # Deal with the zero counts\n",
    "            \n",
    "            # Finally do the summation for Chi2 and append it to list of chi values\n",
    "            chi.append(sum(chi_)) \n",
    "            \n",
    "        \n",
    "        #Find the minimum chi for the current iteration\n",
    "        min_chi = min(chi)  \n",
    " \n",
    "        #Find the first index with minumum chi\n",
    "        for i, v in enumerate(chi):\n",
    "            if v == min_chi:\n",
    "                min_chi_index = i # Find the index of the interval to be merged\n",
    "                break\n",
    "                \n",
    "        \n",
    "        # Prepare for the merged array\n",
    "        new_intervals = [] \n",
    "        skip = False\n",
    "        done = False\n",
    "        \n",
    "        #Merge the intervals found at min_chi_index with next interval\n",
    "        for i in range(len(intervals)):\n",
    "            if skip:\n",
    "                skip = False\n",
    "                continue\n",
    "            if i == min_chi_index and not done: # Merge the intervals\n",
    "                t = intervals[i] + intervals[i+1]\n",
    "                new_intervals.append([min(t), max(t)])\n",
    "                skip = True\n",
    "                done = True\n",
    "            else:\n",
    "                new_intervals.append(intervals[i])\n",
    "        \n",
    "        #Start the chimerge with new set of merged intervals\n",
    "        intervals = new_intervals\n",
    "    \n",
    "    # split points for the attribute\n",
    "    print('\\nSplit points:',attr)\n",
    "    for i in intervals:\n",
    "        print(i[0])\n",
    "        \n",
    "    # intervals for the attribute\n",
    "    print('\\nIntervals:', attr)\n",
    "    for i in intervals:\n",
    "        print('[', i[0], ',', i[1], ']', sep='')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result:\n",
      "\n",
      "Split points: sepal_length\n",
      "4.3\n",
      "4.9\n",
      "5.0\n",
      "5.5\n",
      "5.8\n",
      "7.1\n",
      "\n",
      "Intervals: sepal_length\n",
      "[4.3,4.8]\n",
      "[4.9,4.9]\n",
      "[5.0,5.4]\n",
      "[5.5,5.7]\n",
      "[5.8,7.0]\n",
      "[7.1,7.9]\n",
      "\n",
      "Split points: sepal_width\n",
      "2.0\n",
      "2.3\n",
      "2.5\n",
      "2.9\n",
      "3.0\n",
      "3.4\n",
      "\n",
      "Intervals: sepal_width\n",
      "[2.0,2.2]\n",
      "[2.3,2.4]\n",
      "[2.5,2.8]\n",
      "[2.9,2.9]\n",
      "[3.0,3.3]\n",
      "[3.4,4.4]\n",
      "\n",
      "Split points: petal_length\n",
      "1.0\n",
      "3.0\n",
      "4.5\n",
      "4.8\n",
      "5.0\n",
      "5.2\n",
      "\n",
      "Intervals: petal_length\n",
      "[1.0,1.9]\n",
      "[3.0,4.4]\n",
      "[4.5,4.7]\n",
      "[4.8,4.9]\n",
      "[5.0,5.1]\n",
      "[5.2,6.9]\n",
      "\n",
      "Split points: petal_width\n",
      "0.1\n",
      "1.0\n",
      "1.4\n",
      "1.7\n",
      "1.8\n",
      "1.9\n",
      "\n",
      "Intervals: petal_width\n",
      "[0.1,0.6]\n",
      "[1.0,1.3]\n",
      "[1.4,1.6]\n",
      "[1.7,1.7]\n",
      "[1.8,1.8]\n",
      "[1.9,2.5]\n"
     ]
    }
   ],
   "source": [
    "# applying chi-merge algo on each feature with stopping criteria of maximum 6 intervals\n",
    "print('Result:')\n",
    "for attr in ['sepal_length','sepal_width', 'petal_length', 'petal_width']:\n",
    "    chi_merge(data=iris, attr=attr, label='iris_type', max_intervals=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "351px",
    "left": "995px",
    "right": "20px",
    "top": "120px",
    "width": "351px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
