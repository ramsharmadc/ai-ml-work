{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2 \n",
    "\n",
    "In this assignment, you will try to find groups of similar customers in the dataset included in the uploaded folder. The dataset contains information about credit card behaviour of customers.  \n",
    "\n",
    "\n",
    "### 1. Importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tabulate'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-1f1b75d0848f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHTML\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtabulate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tabulate'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import scipy.cluster.hierarchy as sch\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics import  silhouette_score\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "from IPython.display import HTML, display\n",
    "import tabulate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Reading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('CC GENERAL.csv')\n",
    "print(data.info())\n",
    "print(data.describe())\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Basic pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop('CUST_ID', axis=1)\n",
    "data.head()\n",
    "data.fillna(method ='ffill', inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling \n",
    "mms=MinMaxScaler()\n",
    "data[:] = mms.fit_transform(data[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Finding groups\n",
    "\n",
    "### Approach 1 [ 1.5 + 3.5 marks ] \n",
    "\n",
    "Plot the dendrograms for the above scaled dataset points. (hint: use scipy.cluster.hierarchy imported above). \n",
    "Plot using the following parameters:\n",
    "1. ward\n",
    "2. complete\n",
    "3. average <br> \n",
    "Study the dendrograms and comment on the major differences between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ward\n",
    "Z=sch.linkage(data,method='ward')\n",
    "plt.figure(figsize=(15,10))\n",
    "sch.dendrogram(Z,leaf_rotation=90,p=5,color_threshold=20,leaf_font_size=10,truncate_mode='level')\n",
    "plt.axhline(y=35, color='r', linestyle='--')\n",
    "plt.title(\"Linkage: Ward\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Conclusion:</b> The optimal no. of clusters is <b> 2 </b> as per above dendogram for Ward Linkage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Complete\n",
    "Z=sch.linkage(data,method='complete')\n",
    "plt.figure(figsize=(15,10))\n",
    "sch.dendrogram(Z,leaf_rotation=90,p=5,color_threshold=20,leaf_font_size=10,truncate_mode='level')\n",
    "plt.axhline(y=2.2, color='r', linestyle='--')\n",
    "plt.title(\"Linkage: Complete\")\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Conclusion:</b> The optimal no. of clusters is <b> 6 </b> as per above dendogram for Complete Linkage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Average\n",
    "Z=sch.linkage(data,method='average')\n",
    "plt.figure(figsize=(15,10))\n",
    "sch.dendrogram(Z,leaf_rotation=90,p=5,color_threshold=20,leaf_font_size=10,truncate_mode='level')\n",
    "plt.axhline(y=1.75, color='r', linestyle='--')\n",
    "plt.title(\"Linkage: Average\")\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Conclusion:</b> The optimal no. of clusters is <b> 3 </b> as per above dendogram for Average Linkage. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the help of dendrograms obtained above, choose a suitable **k** for each linkage type. Experiment with different distance measures as mentioned below: <br>\n",
    "1. Euclidean \n",
    "2. Manhattan \n",
    "3. Cosine <br> \n",
    "Calculate the cluster quality for each case and report your results in an organized, tabular format. The table should have the parameters used, cluster means and cluster quality.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clustering (hint: Use AgglomerativeClustering imported above)\n",
    "options = { 'ward': 2, 'complete': 6, 'average': 3 }\n",
    "results = []\n",
    "for linkage in options.keys(): \n",
    "    no_of_clusters = options[linkage] \n",
    "    euclidean_model = AgglomerativeClustering(n_clusters=no_of_clusters, affinity='euclidean', linkage=linkage)\n",
    "    euclidean_model.fit(data)\n",
    "    euclidean_labels = euclidean_model.labels_\n",
    "    silhouette_avg = silhouette_score(data, euclidean_labels)\n",
    "\n",
    "    results.append((linkage, no_of_clusters, 'euclidean', silhouette_avg ))\n",
    "    \n",
    "    if(linkage != 'ward') :\n",
    "        manhattan_model = AgglomerativeClustering(n_clusters=no_of_clusters, affinity='manhattan', linkage=linkage)\n",
    "        manhattan_model.fit(data)\n",
    "        manhattan_labels = manhattan_model.labels_\n",
    "        silhouette_avg = silhouette_score(data, manhattan_labels)\n",
    " \n",
    "        results.append((linkage, no_of_clusters,  'manhattan', silhouette_avg ))\n",
    "        \n",
    "        cosine_model = AgglomerativeClustering(n_clusters=no_of_clusters, affinity='cosine', linkage=linkage)\n",
    "        cosine_model.fit(data)\n",
    "        cosine_labels = cosine_model.labels_\n",
    "        silhouette_avg = silhouette_score(data, cosine_labels)\n",
    "  \n",
    "        results.append((linkage, no_of_clusters,  'cosine', silhouette_avg ))\n",
    "    else:\n",
    "        results.append((linkage, no_of_clusters, 'manhattan', \"NA\" ))\n",
    "        results.append((linkage, no_of_clusters,  'cosine', \"NA\" ))\n",
    "     \n",
    "df = pd.DataFrame(results, columns =['Linkage', 'No. of Clusters', 'Distance Measure', 'Silhouette Score']) \n",
    "df.reset_index(drop=True, inplace=True) \n",
    "display( df )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Conclusion:</b> As per above table, we can conclude that for <b>Euclidean</b> distance performs better for Ward and Complete linkages. <b>Manhattan</b> distance performs better for Average linkage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 2 [ 3 marks] \n",
    "Solve the same problem using a density based approach. Experiment with the following values of eps and minpts:<br> \n",
    "1. eps = 0.1, min_pts = 5\n",
    "2. eps = 0.5, min_pts = 3\n",
    "3. eps = 0.8, min_pts = 5 <br>\n",
    "Analyze the results and comment on how the clustering changes as the above parameters are varied. Report the cluster quality for all the cases using the same measure as used for approach 1. Report results in a tabular format with parameters used, number of noise and core points and cluster quality. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clustering \n",
    "results = []\n",
    "for (eps,min_pts) in ((0.1,5), (0.5, 3), (0.8, 5)):\n",
    "    db = DBSCAN(eps=eps, min_samples=min_pts).fit(data)\n",
    "    core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n",
    "    core_samples_mask[db.core_sample_indices_] = True\n",
    "    labels = db.labels_\n",
    "    n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "    results.append((eps, min_pts, n_clusters, silhouette_score(data, labels) ))\n",
    "\n",
    "df = pd.DataFrame(results, columns =['EPS', 'Min Samples', 'No. of Clusters' , 'Silhouette Score']) \n",
    "df.reset_index(drop=True, inplace=True) \n",
    "display( df )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Conclusion:</b> As per above table, we can conclude that EPS <b>0.8</b> and Min Samples <b>5</b> performs better with DBSCAN Method and it results in <b>4</b> clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualization [ 2 marks ] \n",
    "To visualize the clusters, reduce the data to 2 dimensions using PCA. Make a scatterplot with different colours for each cluster obtained. Make one visualization each for approach 1 and 2 (the parameters which gave the best cluster quality for each). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization - reduce to two dimensions using PCA and make a scatterplot \n",
    "pca = PCA(n_components = 2) \n",
    "X_principal = pca.fit_transform(data) \n",
    "X_principal = pd.DataFrame(X_principal) \n",
    "X_principal.columns = ['P1', 'P2'] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hierarchical Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hierarchical Clustering\n",
    "plt.scatter(X_principal['P1'], X_principal['P2'],  \n",
    "           c = AgglomerativeClustering(n_clusters = 2).fit_predict(X_principal), cmap =plt.cm.winter) \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DBScan Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DBScan\n",
    "plt.scatter(X_principal['P1'], X_principal['P2'],  \n",
    "           c =DBSCAN(eps=0.8, min_samples=5).fit_predict(X_principal), cmap =plt.cm.winter) \n",
    "plt.show() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
